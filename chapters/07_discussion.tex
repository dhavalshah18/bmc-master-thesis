\chapter{Discussion}
\label{chapter7}

In this study, two pre-existing networks were presented and used to assess the validity of our proposed network (Triplanar-Net), against a publicly available (train) dataset for cerebral UIA segmentation. Segmentation metrics are reported for both the train dataset and the non-publicly available dataset (test). The results shown for Triplanar-Net are lower than those reported for the SOTA -- the nnU-Net, however the network performs better than the well established DeepMedic network architecture. All three network architectures still show room for substantial improvement on the test dataset. Compared to the reported interobserver results by \citeauthor{Timmins2020}, the segmentation results are lower. It is also shown that in this study, it is possible to harvest 2D data and attempt to accurately reconstruct and learn 3D labels from it. 

The potential of neural networks to detect and segment UIAs in TOF-MRA's has been demonstrated previously, and the MICCAI2020 ADAM challenge presented by \citeauthor{Timmins2020} was an initiative that encouraged further exploration into this field. The steadily increasing workload of the radiology departments due to the growing necessity of radiological imaging must be managed; the introduction of more computer-aided diagnosis and detection tools in this regard can prove to show great improvement -- by possibly reducing diagnostic errors for example. Segmentations are also able to provide measurements to medical professionals that are beneficial in both a diagnostic and planning scenarios, therefore automatically obtaining these segmentations and measurements would be a valuable addition in a clinical setting.

Based on the reported segmentation metrics, the results of the nnU-Net far surpass the results produced by DeepMedic and by Triplanar-Net on both the train dataset and the test dataset. With a Dice Score Coefficient of 0.81 on the train dataset the nnU-Net shows superior accuracy in terms of segmentation over DeepMedic and Triplanar-Net which have a DSC of 0.11 and 0.14 respectively. The Hausdorff distance is also the least for the nnU-Net architecture with 0.49 mm compared to large values of 59.70 mm for DeepMedic and 53.90 mm for Triplanar-Net (with values closer to 0 mm being the best). The high performance of the nnU-Net reported on the train dataset is also reflected in the test dataset with a DSC of 0.41 and a Hausdorff distance of 8.96, which both DeepMedic and Triplanar-Net could not surpass. 
The sensitivities of the three frameworks show some more similarities than the segmentation metrics, with nnU-Net outperforming DeepMedic and Triplanar-Net in the train dataset. However, DeepMedic shows to outperform both nnU-Net and Triplanar-Net with a sensitivity of 0.85 compared to 0.61 and 0.76 respectively. This could however be because of the large False Positive Count, i.e. DeepMedic has a fewer amount of false negatives due to the fact that it contains much more positive detections. In Figure \ref{fig:results} it is easily seen that the nnU-Net architecture also performs much more uniformly than DeepMedic and Triplanar-Net. Although there are some outliers in terms of DSC and VS for nnU-Net, both DeepMedic and Triplanar-Net show more variance in all cases, as well as more outliers so the segmentation accuracy is highly dependent for each individual case and could suggest that these networks were not able to generalize well on the dataset. 

Triplanar-Net does outperform DeepMedic in all metrics across the board for both the train and test dataset -- with sensitivity being the only exception. The average false positive count of Triplanar-Net particularly is much better than that of DeepMedic. The proposed network however cannot come near the results put forth by the SOTA. DeepMedic reported a DSC of 0.50 and sensitivity and false positive count of 0.90 and 6.1 respectively in their study, which is dramatically different from the achieved results in this study. This could show that the dataset is more difficult to perform accurate segmentations on than the one used in their study. The dataset used in their study did not have any negative cases and this is a possible reason for the number of false positives for the current dataset being so high for the network. 

Taking a look at the results of the further evaluations: considering inference time of each network, nnU-Net is very resource intensive with almost 150 times more parameters than both DeepMedic and Triplanar-Net. Using a larger network -- one with more parameters -- is most likely one of the reasons the nnU-Net outperforms both the other two networks. nnU-Net and DeepMedic both use only 3D convolutions, and thus the inference time per case (not including pre- and postprocessing) is much larger than that of Triplanar-Net which combines the use of both 2D and 3D convolution operations. It is surprising that DeepMedic contains a slightly smaller amount of parameters than Triplanar-Net but takes almost the same amount of inference time as nnU-Net; this could be accounted by the parameters introduced in Triplanar-Net by adding the skip connections which are not present in DeepMedic. Even though the time to infer could be considered a valuable metric if an automated system is employed in a real-time clinical setting, if the segmentation accuracy cannot be on par with the SOTA then this cannot be deemed an important factor, and the same can be said for the number of parameters.

Evaluating segmentation performance of the networks on only true positive detections also made an impact: both the DSC and MHD are seen to improve for the DeepMedic architecture and for the Triplanar-Net architecture. The nnU-Net framework nonetheless still outperforms the other two architectures. It is interesting to note that DeepMedic outperforms Triplanar-Net in all metrics when only considering true UIAs, showing that the accuracy of the segmentation if ignoring any false positives is actually slightly better than Triplanar-Net. When taking a further look into the performance on negative scans, it can be seen that DeepMedic has the highest number of False positives for both negative and positive cases, with the false positive count for negative scans being drastically greater than that for positive scans. The nnU-Net framework detects 0 false positives throughout all scans in the train dataset which is an impressive feat; although Triplanar-Net does not have a large variance between false positives on positive and negative scans, the number is still large in and of itself. 

Taking a look at Figure \ref{fig:qual_results} it can be seen that all three network architectures show better DSCs for cases with larger aneurysm sizes. The nnU-Net framework also seems to struggle for very small aneurysms (even though the mean DSC value for small aneurysms is around 0.80). Although both DeepMedic and Triplanar-Net do show better performance for larger aneurysms (with a median of around 0.20 and 0.38 respectively) the box plots show a large inter-quartile range, i.e. the results are not very uniform in those instances.

The performance of nnU-Net shows to drop drastically between the train dataset and the test dataset, suggesting that although the framework shows exceptional performance on the train dataset it may not be able to generalize well to the test dataset. Although nnU-Net performed better with respect to the DSC and MHD, Triplanar-Net showed a better Volumetric Similarity for test dataset. The Triplanar-Net and DeepMedic architectures also reported a much smaller difference in segmentation metrics on the train and test dataset. As stated by \citeauthor{Timmins2020} the characteristics such as the distribution of aneurysms of the train and test dataset are similar, so the train dataset is ensured to be representative of the test dataset. Therefore the reason for the poorer performance could lie in factors such as the train/validation split during training, aneurysm sizes. However it is also difficult to account for changes in aneurysm shapes or differences in parent vessels. In a clinical setting the uniformity of images and conditions cannot be replied upon and so ideally methods should be able to detect and segment UIAs on unseen examples too.

The axial slices of the three cases in Figure \ref{fig:qual_results} show once again the superior performance of the nnU-Net architecture over DeepMedic and Triplanar-Net: the shape of the aneurysm is captured more accurately, and there are no false positive detections. Triplanar-Net and DeepMedic both do seem to detect an aneurysm in similar locations to nnU-Net but the segmentation itself is lacking.

In a clinical setting, the segmentation result of nnU-Net, DeepMedic and Triplanar-Net would not be beneficial; the interobserver measurements as reported by \citeauthor{Timmins2020} are all more accurate than the three evaluated networks. However, when evaluating results of only true UIAs, nnU-Net shows results equivalent to the interobserver DSC. This suggests that once the true UIA is found the automatic segmentation method is on par with the manual segmentation. From literature, the sensitivity of detecting an UIA in 3D TOF-MRA is approximately 86\% (much lower for smaller aneurysms), and in this case DeepMedic does perform on par with manual detection. Howeverl the false positive count is well above what could considered be reasonable and in practice this overload of positive detections would not be beneficial for the medical professionals \citeauthor{Sailer2014, White2001}. Similarly, due to the high false positive count of Triplanar-Net, a compelling argument to introduce it within a clinical workflow cannot be given.

With these results before us it can be said that Triplanar-Net does not perform as expected, and that attempting to segment aneurysms in 3D TOF-MRA images using 2D MIP views was not successful. Although Triplanar-Net performs almost on par with DeepMedic -- which is a 3D network -- it can be said that the loss of 3D context while using Triplanar-Net was its downfall. Although the use of 2D MIPs in the case of spine CT images seems to show good results for the Btrfly-Net, the task of aneurysm segmentation is much more imbalanced. The task of aneurysm segmentation in TOF-MRA images is itself a hard one, and attempting to reduce the number of parameters and improve on inference time for use in a clinical setting was not possible as the network could not generalize well. Some small changes such as making the architecture deeper or increasing the number of feature maps in each layer are possible future areas of work, however the area most in need of improvement and/or further testing could be the 2D to 3D reconstruction block. Different ensembles could also be tested for further justification or proof of concept in this regard. Much like many other deep learning methods, an increase in the number of cases used to train the network could also be a valuable area of future exploration. The full pipeline detailed in \ref{appendix1} is also an interesting approach that can be further explored if it is possible to increase achieved sensitivity and specificity of the classifier network. The winning method for detection in the ADAM challenge only achieved a maximum sensitivity of 0.70 in the test dataset, showing that this is also a difficult task requiring much more research and experimentation.







